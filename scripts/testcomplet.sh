    local datasets=($(jq -r '[.enabled_datasets // {} | to_entries[]] | .[] | select(.value.auto_download == true) | .key' "$CONFIG_DIR/datasets-status.json"))
#!/bin/bash

# =============================================================================
# TESTCOMPLET.SH - Test de bout en bout pour EarthImagery
# =============================================================================
# Ce script effectue un test complet du pipeline EarthImagery :
# 1. Nettoyage de toutes les donn√©es existantes
# 2. T√©l√©chargement de 10 jours de donn√©es pour les datasets actifs
# 3. G√©n√©ration des fragments vid√©o journaliers
# 4. Cr√©ation des playlists HLS
#
# Usage: ./testcomplet.sh
# =============================================================================

set -euo pipefail

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
DATA_DIR="$PROJECT_ROOT/public/data"
CONFIG_DIR="$PROJECT_ROOT/config"
TRACKING_FILE="$CONFIG_DIR/download-tracking.json"
LOG_FILE="$DATA_DIR/logs/testcomplet-$(date +%Y%m%d-%H%M%S).log"

# Couleurs pour les logs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# =============================================================================
# FONCTIONS UTILITAIRES
# =============================================================================

log() {
    local level="$1"
    shift
    local message="$*"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    case "$level" in
        "INFO")  echo -e "${GREEN}[INFO]${NC} $timestamp - $message" | tee -a "$LOG_FILE" ;;
        "WARN")  echo -e "${YELLOW}[WARN]${NC} $timestamp - $message" | tee -a "$LOG_FILE" ;;
        "ERROR") echo -e "${RED}[ERROR]${NC} $timestamp - $message" | tee -a "$LOG_FILE" ;;
        "DEBUG") echo -e "${BLUE}[DEBUG]${NC} $timestamp - $message" | tee -a "$LOG_FILE" ;;
    esac
}

# Fonction pour construire le chemin de donn√©es satellite avec structure NOAA/EUMETSAT
build_satellite_data_path() {
    local dataset_key="$1"
    local date="$2"
    
    # R√©cup√©rer la source du dataset depuis la configuration
    local source=$(jq -r ".enabled_datasets[\"$dataset_key\"].source // \"UNKNOWN\"" "$CONFIG_DIR/datasets-status.json")
    
    # Conversion du dataset key en chemin: GOES19.car.GEOCOLOR.4000x4000 -> NOAA/GOES19/car/GEOCOLOR/4000x4000
    IFS='.' read -ra PARTS <<< "$dataset_key"
    if [ ${#PARTS[@]} -eq 4 ]; then
        local satellite="${PARTS[0]}"
        local sector="${PARTS[1]}"
        local product="${PARTS[2]}"
        local resolution="${PARTS[3]}"
        
        case "$source" in
            "NOAA")
                # Structure NOAA: NOAA/satellite/sector/product/resolution/date
                echo "$DATA_DIR/NOAA/$satellite/$sector/$product/$resolution/$date"
                ;;
            "EUMETSAT")
                # Structure EUMETSAT: EUMETSAT/satellite/sector/product/resolution/date
                echo "$DATA_DIR/EUMETSAT/$satellite/$sector/$product/$resolution/$date"
                ;;
            *)
                # Fallback vers structure classique pour sources inconnues
                echo "$DATA_DIR/$satellite/$sector/$product/$resolution/$date"
                ;;
        esac
    else
        # Fallback vers l'ancienne m√©thode si le format n'est pas reconnu
        local dataset_path=$(echo "$dataset_key" | tr '.' '/')
        echo "$DATA_DIR/$dataset_path/$date"
    fi
}

create_directories() {
    log "INFO" "Cr√©ation des r√©pertoires n√©cessaires..."
    mkdir -p "$DATA_DIR/logs"
    mkdir -p "$DATA_DIR/images"
    mkdir -p "$DATA_DIR/hls"
    mkdir -p "$CONFIG_DIR"
}

check_dependencies() {
    log "INFO" "V√©rification des d√©pendances..."
    
    local missing_deps=()
    
    if ! command -v jq &> /dev/null; then
        missing_deps+=("jq")
    fi
    
    if ! command -v ffmpeg &> /dev/null; then
        missing_deps+=("ffmpeg")
    fi
    
    if ! command -v curl &> /dev/null; then
        missing_deps+=("curl")
    fi
    
    if [ ${#missing_deps[@]} -ne 0 ]; then
        log "ERROR" "D√©pendances manquantes: ${missing_deps[*]}"
        log "ERROR" "Veuillez installer: sudo apt install ${missing_deps[*]}"
        exit 1
    fi
    
    log "INFO" "Toutes les d√©pendances sont pr√©sentes"
}

# =============================================================================
# PHASE 1: D√âTECTION DES JOURS √Ä TRAITER
# =============================================================================

detect_days_to_process() {
    log "INFO" "üîé PHASE 1: D√©tection optimis√©e des jours √† traiter par dataset"
    
    # Variables globales pour stocker les r√©sultats
    declare -gA DATASET_DAYS_TO_PROCESS  # Associative array: dataset_key -> "jour1 jour2 jour3"
    declare -ga ALL_DAYS_TO_PROCESS      # Array de tous les jours uniques √† traiter
    
    local today=$(date +%Y-%m-%d)
    local yesterday=$(date -d "yesterday" +%Y-%m-%d)
    
    # R√©cup√©rer la liste des datasets actifs (incluant les datasets virtuels pour d√©tection vid√©o)
    local datasets=($(jq -r '[.enabled_datasets // {} | to_entries[]] | .[] | select(.value.auto_download == true or .value.virtual_dataset == true) | .key' "$CONFIG_DIR/datasets-status.json"))
    
    log "INFO" "Analyse de ${#datasets[@]} dataset(s) actif(s) sur les 10 derniers jours..."
    
    for dataset_key in "${datasets[@]}"; do
        # Le dataset_key correspond d√©j√† au nom de dossier HLS (garder les points)
        local dataset_path="$dataset_key"
        local days_for_dataset=()
        
        # Analyser les 10 derniers jours pour ce dataset sp√©cifique
        for i in {0..1}; do
            local day=$(date -d "$today -$i day" +%Y-%m-%d)
            local hls_dataset_dir="$DATA_DIR/hls/$dataset_path/$day"
            
            # V√©rifier si ce dataset a une playlist et des segments pour ce jour
            local has_playlist=0
            local has_segments=0
            
            if [ -f "$hls_dataset_dir/playlist.m3u8" ]; then
                has_playlist=1
            fi
            
            if [ -n "$(find "$hls_dataset_dir" -name "*.ts" -type f 2>/dev/null | head -1)" ]; then
                has_segments=1
            fi
            
            # Si manquant, ajouter ce jour pour ce dataset
            if [ "$has_playlist" -eq 0 ] || [ "$has_segments" -eq 0 ]; then
                days_for_dataset+=("$day")
            fi
        done
        
        # Toujours inclure aujourd'hui et hier pour tous les datasets (politique de fra√Æcheur)
        [[ ! " ${days_for_dataset[@]} " =~ " $today " ]] && days_for_dataset+=("$today")
        [[ ! " ${days_for_dataset[@]} " =~ " $yesterday " ]] && days_for_dataset+=("$yesterday")
        
        # Stocker les jours pour ce dataset (tri√©s et uniques)
        DATASET_DAYS_TO_PROCESS["$dataset_key"]=$(printf "%s\n" "${days_for_dataset[@]}" | sort -u | tr '\n' ' ')
        
        # Ajouter √† la liste globale de tous les jours
        ALL_DAYS_TO_PROCESS+=(${days_for_dataset[@]})
        
        local day_count=${#days_for_dataset[@]}
        log "INFO" "  üìä $dataset_key: $day_count jour(s) √† traiter"
    done
    
    # Cr√©er la liste unique et tri√©e de tous les jours
    ALL_DAYS_TO_PROCESS=($(printf "%s\n" "${ALL_DAYS_TO_PROCESS[@]}" | sort -u))
    
    log "INFO" "üéØ R√©sum√©: ${#ALL_DAYS_TO_PROCESS[@]} jour(s) unique(s) √† traiter au total"
    log "INFO" "Jours concern√©s: ${ALL_DAYS_TO_PROCESS[*]}"
}

# =============================================================================
# PHASE 2: T√âL√âCHARGEMENT DES DONN√âES (SCRIPTS DE PRODUCTION)
# =============================================================================


download_active_datasets() {
    log "INFO" "üì• PHASE 2: T√©l√©chargement optimis√© par dataset"
    # V√©rifier que les scripts de production existent
    local required_scripts=(
        "$SCRIPT_DIR/smart-fetch.sh"
        "$SCRIPT_DIR/generate-historical-data.sh"
    )
    for script in "${required_scripts[@]}"; do
        if [ ! -f "$script" ]; then
            log "ERROR" "Script de production manquant: $script"
            exit 1
        fi
    done
    log "INFO" "‚úÖ Tous les scripts de production sont disponibles"
    
    # R√©cup√©rer la liste des datasets actifs (auto_download: true) EXCLUANT les datasets virtuels
    local datasets=($(jq -r '[.enabled_datasets // {} | to_entries[]] | .[] | select(.value.auto_download == true and (.value.virtual_dataset != true)) | .key' "$CONFIG_DIR/datasets-status.json"))
    if [ ${#datasets[@]} -eq 0 ]; then
        log "WARN" "Aucun dataset actif trouv√© pour le t√©l√©chargement."
        return 1
    fi
    
    local total_downloads=0
    local failed_downloads=0
    
    # T√©l√©charger seulement les jours n√©cessaires pour chaque dataset
    for dataset_key in "${datasets[@]}"; do
        local days_str="${DATASET_DAYS_TO_PROCESS[$dataset_key]}"
        if [ -z "$days_str" ]; then
            log "INFO" "üìä $dataset_key: Aucun jour √† t√©l√©charger (d√©j√† complet)"
            continue
        fi
        
        # R√©cup√©rer la source du dataset
        local source=$(jq -r ".enabled_datasets[\"$dataset_key\"].source // \"UNKNOWN\"" "$CONFIG_DIR/datasets-status.json")
        
        # Convertir la cha√Æne en array
        local days_array=($days_str)
        log "INFO" "üì• $dataset_key ($source): ${#days_array[@]} jour(s) √† t√©l√©charger"
        
        for day in "${days_array[@]}"; do
            # Utilisation de la nouvelle fonction pour g√©rer la structure NOAA/EUMETSAT
            local images_dir=$(build_satellite_data_path "$dataset_key" "$day")
            
            # Suppression des images corrompues (taille nulle) avant t√©l√©chargement
            local corrupted_count=$(find "$images_dir" -type f \( -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" \) -size 0 -delete -print 2>/dev/null | wc -l)
            if [ "$corrupted_count" -gt 0 ]; then
                log "WARN" "    üßπ $corrupted_count image(s) corrompue(s) supprim√©e(s) dans $images_dir"
            fi
            
            log "INFO" "  üì• T√©l√©chargement $dataset_key pour $day"
            total_downloads=$((total_downloads + 1))
            
            # Utiliser smart-fetch.sh unifi√© pour toutes les sources
            if bash "$SCRIPT_DIR/smart-fetch.sh" dataset "$dataset_key" "$day" "$day" 2>&1 | tee -a "$LOG_FILE"; then
                log "INFO" "    ‚úÖ Images t√©l√©charg√©es pour $dataset_key le $day ($source)"
            else
                log "WARN" "    ‚ö†Ô∏è smart-fetch.sh a √©chou√© pour $dataset_key le $day"
                failed_downloads=$((failed_downloads + 1))
                
                # Tentative de r√©cup√©ration avec generate-historical-data pour NOAA uniquement
                if [ "$source" = "NOAA" ]; then
                    log "INFO" "    ‚Ü™Ô∏è Tentative de g√©n√©ration historique pour $dataset_key le $day"
                    if bash "$SCRIPT_DIR/generate-historical-data.sh" "$day" "$day" 2>&1 | tee -a "$LOG_FILE"; then
                        log "INFO" "    ‚úÖ generate-historical-data.sh r√©ussi pour $day"
                    else
                        log "WARN" "    ‚ùå generate-historical-data.sh a aussi √©chou√© pour $day"
                    fi
                fi
            fi
        done
    done
    
    # R√©sum√© des t√©l√©chargements
    log "INFO" "üìä R√©sum√© t√©l√©chargements: $total_downloads tentative(s), $failed_downloads √©chec(s)"
    
    # V√©rifier que des donn√©es ont √©t√© t√©l√©charg√©es
    local image_count=$(find "$DATA_DIR" -name "*.jpg" -o -name "*.png" -type f | wc -l)
    log "INFO" "üìä Images total dans le syst√®me: $image_count"
    if [ "$image_count" -eq 0 ]; then
        log "WARN" "‚ö†Ô∏è Aucune image dans le syst√®me"
    fi
    log "INFO" "‚úÖ Phase de t√©l√©chargement optimis√©e termin√©e"
}

# =============================================================================
# PHASE 3: G√âN√âRATION DES VID√âOS (SCRIPTS DE PRODUCTION)
# =============================================================================


generate_daily_videos() {
    log "INFO" "üé¨ PHASE 3: G√©n√©ration vid√©o optimis√©e par dataset"
    if [ ! -f "$SCRIPT_DIR/generate-daily-video.sh" ]; then
        log "ERROR" "Script de production manquant: generate-daily-video.sh"
        exit 1
    fi
    
    local image_count=$(find "$DATA_DIR" -name "*.jpg" -type f | wc -l)
    if [ "$image_count" -eq 0 ]; then
        log "WARN" "Aucune image trouv√©e pour g√©n√©rer des vid√©os"
        return 0
    fi
    
    # R√©cup√©rer la liste des datasets avec g√©n√©ration vid√©o activ√©e (incluant les datasets virtuels)
    local datasets=($(jq -r '[.enabled_datasets // {} | to_entries[]] | .[] | select((.value.auto_download == true or .value.virtual_dataset == true) and (.value.video_generation != false)) | .key' "$CONFIG_DIR/datasets-status.json"))
    
    local total_generations=0
    local successful_generations=0
    
    # G√©n√©rer les vid√©os seulement pour les couples dataset+jour n√©cessaires
    for dataset_key in "${datasets[@]}"; do
        local days_str="${DATASET_DAYS_TO_PROCESS[$dataset_key]}"
        if [ -z "$days_str" ]; then
            log "INFO" "üìä $dataset_key: Aucune vid√©o √† g√©n√©rer (d√©j√† complet)"
            continue
        fi
        
        # Convertir la cha√Æne en array
        local days_array=($days_str)
        log "INFO" "üé¨ $dataset_key: ${#days_array[@]} jour(s) √† traiter"
        
        for day in "${days_array[@]}"; do
            # V√©rifier si c'est un dataset virtuel
            local virtual_info=$(jq -r --arg key "$dataset_key" '
                .enabled_datasets[$key] | 
                if .virtual_dataset == true then 
                    {"is_virtual": true, "parent_dataset": .parent_dataset}
                else 
                    {"is_virtual": false}
                end
            ' "$CONFIG_DIR/datasets-status.json" 2>/dev/null)
            
            local is_virtual=$(echo "$virtual_info" | jq -r '.is_virtual // false')
            local images_dir=""
            
            if [ "$is_virtual" = "true" ]; then
                # Dataset virtuel : utiliser le dossier d'images du parent
                local parent_dataset=$(echo "$virtual_info" | jq -r '.parent_dataset // ""')
                if [ -n "$parent_dataset" ]; then
                    images_dir=$(build_satellite_data_path "$parent_dataset" "$day")
                    log "INFO" "  üîÑ Dataset virtuel $dataset_key ‚Üí utilise images de $parent_dataset"
                else
                    log "WARN" "  ‚ùå Dataset virtuel $dataset_key sans parent_dataset d√©fini"
                    continue
                fi
            else
                # Dataset normal
                images_dir=$(build_satellite_data_path "$dataset_key" "$day")
            fi
            
            # Suppression des images corrompues (taille nulle)
            local corrupted_count=$(find "$images_dir" -type f \( -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" \) -size 0 -delete -print 2>/dev/null | wc -l)
            if [ "$corrupted_count" -gt 0 ]; then
                log "WARN" "    üßπ $corrupted_count image(s) corrompue(s) supprim√©e(s) dans $images_dir"
            fi
            
            local img_count=$(find "$images_dir" -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" -type f 2>/dev/null | wc -l)
            if [ "$img_count" -eq 0 ]; then
                log "INFO" "    ‚è© Aucune image pour $dataset_key le $day, g√©n√©ration saut√©e"
                continue
            fi
            
            log "INFO" "  üìπ G√©n√©ration $dataset_key pour $day ($img_count images)"
            total_generations=$((total_generations + 1))
            
            if bash "$SCRIPT_DIR/generate-daily-video.sh" "$dataset_key" "$day" >> "$LOG_FILE" 2>&1; then
                log "INFO" "    ‚úÖ Vid√©o g√©n√©r√©e avec succ√®s pour $dataset_key le $day"
                successful_generations=$((successful_generations + 1))
            else
                log "WARN" "    ‚ùå √âchec g√©n√©ration vid√©o pour $dataset_key le $day"
            fi
        done
    done
    
    # Comptage final optimis√©
    log "INFO" "üìä R√©sum√© g√©n√©ration: $successful_generations/$total_generations vid√©os g√©n√©r√©es avec succ√®s"
    
    # Compteur global : nombre de couples segment_000.ts + playlist.m3u8
    local hls_dirs=$(find "$DATA_DIR/hls" -type d)
    local video_count=0
    for dir in $hls_dirs; do
        if [ -f "$dir/segment_000.ts" ] && [ -f "$dir/playlist.m3u8" ]; then
            video_count=$((video_count+1))
        fi
    done
    log "INFO" "üìä Vid√©os g√©n√©r√©es (couples ts/m3u8): $video_count"
    log "INFO" "‚úÖ Phase de g√©n√©ration vid√©o termin√©e"
}

# =============================================================================
# PHASE 4: CR√âATION DES PLAYLISTS
# =============================================================================

create_playlists() {
    log "INFO" "üìã PHASE 4: Cr√©ation des playlists HLS"
    
    # Les playlists sont normalement cr√©√©es par generate-daily-video.sh
    # V√©rifions qu'elles existent et comptons-les
    
    local playlist_count=$(find "$DATA_DIR/hls" -name "playlist.m3u8" -type f | wc -l)
    local segment_count=$(find "$DATA_DIR/hls" -name "*.ts" -type f | wc -l)
    
    log "INFO" "Playlists HLS cr√©√©es: $playlist_count"
    log "INFO" "Segments vid√©o cr√©√©s: $segment_count"
    
    if [ "$playlist_count" -gt 0 ]; then
        log "INFO" "Structure des playlists: $playlist_count playlists trouv√©es"
        # Affichage simple sans boucle potentiellement probl√©matique
        log "INFO" "  Exemples de playlists disponibles dans le r√©pertoire hls/"
        if [ "$playlist_count" -gt 5 ]; then
            log "INFO" "  (affichage de 5 exemples sur $playlist_count total)"
        fi
    fi
    
    log "INFO" "‚úÖ Playlists HLS disponibles"
    log "INFO" "üîö FIN de create_playlists() - passage √† la suite"
}

# =============================================================================
# PHASE 5: VALIDATION ET RAPPORT
# =============================================================================

generate_report() {
    log "INFO" "üìä PHASE 5: G√©n√©ration du rapport final"
    
    # Statistiques finales
    local total_images=$(find "$DATA_DIR" -name "*.jpg" -type f | wc -l)
    local total_videos=0
    for day in "$@"; do
        for dataset_key in "${datasets[@]}"; do
            local hls_dir="$DATA_DIR/hls/$dataset_key/$day"
            if [ -f "$hls_dir/segment_000.ts" ] && [ -f "$hls_dir/playlist.m3u8" ]; then
                total_videos=$((total_videos+1))
            fi
        done
    done
    local total_playlists=$(find "$DATA_DIR/hls" -name "playlist.m3u8" -type f | wc -l)
    local total_segments=$(find "$DATA_DIR/hls" -name "*.ts" -type f | wc -l)
    local data_size=$(du -sh "$DATA_DIR" 2>/dev/null | cut -f1)
    
    echo ""
    echo "========================================="
    echo "üìä RAPPORT FINAL - TEST COMPLET"
    echo "========================================="
    echo "üñºÔ∏è  Images t√©l√©charg√©es: $total_images"
    echo "üé¨ Vid√©os g√©n√©r√©es: $total_videos"  
    echo "üìã Playlists HLS: $total_playlists"
    echo "üéûÔ∏è  Segments vid√©o: $total_segments"
    echo "üíæ Taille totale des donn√©es: $data_size"
    echo ""
    
    if [ "$total_images" -gt 0 ] && [ "$total_playlists" -gt 0 ]; then
        echo "‚úÖ TEST COMPLET R√âUSSI!"
        echo ""
        echo "üöÄ L'application frontend peut maintenant:"
        echo "   - Afficher les datasets disponibles"
        echo "   - Lire les vid√©os satellitaires"
        echo "   - Naviguer dans les playlists HLS"
        echo ""
        echo "üåê D√©marrez le serveur avec: npm run dev"
        echo "üì± Acc√©dez √†: http://localhost:10000"
    else
        echo "‚ùå TEST INCOMPLET"
        echo "   V√©rifiez les logs pour plus de d√©tails: $LOG_FILE"
    fi
    
    echo "========================================="
    echo ""
}

# =============================================================================
# FONCTION PRINCIPALE
# =============================================================================


main() {
    echo ""
    echo "üåç EarthImagery - Test de bout en bout (Scripts de Production)"
    echo "============================================================="
    echo ""
    echo "Ce test ex√©cute directement les scripts qui tourneront en production:"
    echo "  üì• Phase 2: T√©l√©chargement cibl√©"
    echo "  üé¨ Phase 3: G√©n√©ration vid√©o cibl√©e"
    echo "  üìã Phase 4: Validation des playlists HLS g√©n√©r√©es"
    echo ""
    # Initialisation
    create_directories
    check_dependencies
    # D√©tection des jours √† traiter
    detect_days_to_process
    # Ex√©cution des phases avec les scripts de production
    download_active_datasets
    generate_daily_videos
    create_playlists
    log "INFO" "‚úÖ create_playlists() termin√© - passage au comptage HLS"
    
    # Comptage simple du nombre total de playlists HLS existantes (plus rapide)
    local total_hls_playlists=$(find "$DATA_DIR/hls" -name "playlist.m3u8" -type f | wc -l)
    log "INFO" "üìä Total de playlists HLS dans le syst√®me: $total_hls_playlists"
    log "INFO" "‚úÖ Comptage termin√© - passage √† generate_report"
    
    generate_report "${ALL_DAYS_TO_PROCESS[@]}"
    log "INFO" "‚úÖ generate_report() termin√© - passage au nettoyage"
    
    # =============================================================================
    # PHASE 6: NETTOYAGE DES ANCIENNES IMAGES
    # =============================================================================
    log "INFO" "üßπ PHASE 6: D√âBUT du nettoyage des r√©pertoires d'images anciens"
    
    # Suppression des r√©pertoires d'images de plus de 2 jours (garde seulement aujourd'hui et hier)
    local today=$(date +%Y-%m-%d)
    local yesterday=$(date -d "yesterday" +%Y-%m-%d)
    
    log "INFO" "üßπ Suppression des r√©pertoires d'images de plus de 2 jours (garde seulement $today et $yesterday)"
    
    local deleted_dirs=0
    local kept_dirs=0
    local processed_dirs=0
    
    # Fonction interne pour nettoyer les anciens r√©pertoires
    cleanup_old_images() {
        local base_dir="$1"
        local dir_name="$2"
        
        log "INFO" "üîç D√âBUT nettoyage dans $base_dir ($dir_name)"
        
        # V√©rifier que le r√©pertoire existe
        if [ ! -d "$base_dir" ]; then
            log "WARN" "R√©pertoire $base_dir n'existe pas, ignor√©"
            return
        fi
        
        # Chercher tous les r√©pertoires de dates dans cette base
        while IFS= read -r -d '' dir; do
            processed_dirs=$((processed_dirs + 1))
            
            # Extraire la date du nom du r√©pertoire
            local dir_date=$(basename "$dir")
            
            # V√©rifier que la date extraite est valide
            if ! date -d "$dir_date" >/dev/null 2>&1; then
                log "WARN" "Date invalide '$dir_date' dans $dir (conserv√© par s√©curit√©)"
                kept_dirs=$((kept_dirs + 1))
                continue
            fi
            
            # Supprimer si le r√©pertoire n'est ni d'aujourd'hui ni d'hier
            if [ "$dir_date" != "$today" ] && [ "$dir_date" != "$yesterday" ]; then
                # V√©rifier s'il contient des images avant suppression
                local img_count=$(find "$dir" -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" -type f 2>/dev/null | wc -l)
                
                log "INFO" "Suppression r√©pertoire ancien ($dir_date): $dir ($img_count images)"
                rm -rf "$dir"
                deleted_dirs=$((deleted_dirs + 1))
            else
                local img_count=$(find "$dir" -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" -type f 2>/dev/null | wc -l)
                log "DEBUG" "Conservation r√©pertoire r√©cent ($dir_date): $dir ($img_count images)"
                kept_dirs=$((kept_dirs + 1))
            fi
        done < <(find "$base_dir" -type d -name "[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]" -print0 2>/dev/null)
    }
    
    # Nettoyer SEULEMENT les r√©pertoires d'images (pas les HLS)
    log "INFO" "üîÑ Appel cleanup_old_images pour EUMETSAT..."
    cleanup_old_images "$DATA_DIR/EUMETSAT" "EUMETSAT"
    log "INFO" "üîÑ Appel cleanup_old_images pour NOAA..."
    cleanup_old_images "$DATA_DIR/NOAA" "NOAA"
    
    log "INFO" "üßπ Nettoyage termin√©: $deleted_dirs r√©pertoire(s) supprim√©(s), $kept_dirs conserv√©(s) sur $processed_dirs trait√©(s)"
    log "INFO" "‚úÖ PHASE 6: Nettoyage des anciennes images TERMIN√â"
    log "INFO" "üéâ Test complet termin√© - Log disponible: $LOG_FILE"
    log "INFO" "üèÅ FIN D'EX√âCUTION DE TESTCOMPLET.SH"
}

# =============================================================================
# POINT D'ENTR√âE
# =============================================================================

if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
