    local datasets=($(jq -r '[.enabled_datasets // {} | to_entries[]] | .[] | select(.value.auto_download == true) | .key' "$CONFIG_DIR/datasets-status.json"))
#!/bin/bash

# =============================================================================
# TESTCOMPLET.SH - Test de bout en bout pour EarthImagery
# =============================================================================
# Ce script effectue un test complet du pipeline EarthImagery :
# 1. Nettoyage de toutes les donnÃ©es existantes
# 2. TÃ©lÃ©chargement de 10 jours de donnÃ©es pour les datasets actifs
# 3. GÃ©nÃ©ration des fragments vidÃ©o journaliers
# 4. CrÃ©ation des playlists HLS
#
# Usage: ./testcomplet.sh
# =============================================================================

set -euo pipefail

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
DATA_DIR="$PROJECT_ROOT/public/data"
CONFIG_DIR="$PROJECT_ROOT/config"
TRACKING_FILE="$CONFIG_DIR/download-tracking.json"
LOG_FILE="$DATA_DIR/logs/testcomplet-$(date +%Y%m%d-%H%M%S).log"

# Couleurs pour les logs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# =============================================================================
# FONCTIONS UTILITAIRES
# =============================================================================

log() {
    local level="$1"
    shift
    local message="$*"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    case "$level" in
        "INFO")  echo -e "${GREEN}[INFO]${NC} $timestamp - $message" | tee -a "$LOG_FILE" ;;
        "WARN")  echo -e "${YELLOW}[WARN]${NC} $timestamp - $message" | tee -a "$LOG_FILE" ;;
        "ERROR") echo -e "${RED}[ERROR]${NC} $timestamp - $message" | tee -a "$LOG_FILE" ;;
        "DEBUG") echo -e "${BLUE}[DEBUG]${NC} $timestamp - $message" | tee -a "$LOG_FILE" ;;
    esac
}

create_directories() {
    log "INFO" "CrÃ©ation des rÃ©pertoires nÃ©cessaires..."
    mkdir -p "$DATA_DIR/logs"
    mkdir -p "$DATA_DIR/images"
    mkdir -p "$DATA_DIR/hls"
    mkdir -p "$CONFIG_DIR"
}

check_dependencies() {
    log "INFO" "VÃ©rification des dÃ©pendances..."
    
    local missing_deps=()
    
    if ! command -v jq &> /dev/null; then
        missing_deps+=("jq")
    fi
    
    if ! command -v ffmpeg &> /dev/null; then
        missing_deps+=("ffmpeg")
    fi
    
    if ! command -v curl &> /dev/null; then
        missing_deps+=("curl")
    fi
    
    if [ ${#missing_deps[@]} -ne 0 ]; then
        log "ERROR" "DÃ©pendances manquantes: ${missing_deps[*]}"
        log "ERROR" "Veuillez installer: sudo apt install ${missing_deps[*]}"
        exit 1
    fi
    
    log "INFO" "Toutes les dÃ©pendances sont prÃ©sentes"
}

# =============================================================================
# PHASE 1: DÃ‰TECTION DES JOURS Ã€ TRAITER
# =============================================================================

detect_days_to_process() {
    log "INFO" "ğŸ” PHASE 1: DÃ©tection des jours Ã  traiter (fragments/playlists manquants)"
    DAYS_TO_PROCESS=()
    local today=$(date +%Y-%m-%d)
    local yesterday=$(date -d "yesterday" +%Y-%m-%d)
    for i in {0..9}; do
        local day=$(date -d "$today -$i day" +%Y-%m-%d)
        local has_playlist=$(find "$DATA_DIR/hls" -type f -path "*/$day/playlist.m3u8" | grep -q . && echo 1 || echo 0)
        local has_segments=$(find "$DATA_DIR/hls" -type f -path "*/$day/*.ts" | grep -q . && echo 1 || echo 0)
        if [ "$has_playlist" -eq 0 ] || [ "$has_segments" -eq 0 ]; then
            DAYS_TO_PROCESS+=("$day")
        fi
    done
    # Toujours inclure aujourd'hui et la veille (mÃªme s'ils sont complets)
    [[ ! " ${DAYS_TO_PROCESS[@]} " =~ " $today " ]] && DAYS_TO_PROCESS+=("$today")
    [[ ! " ${DAYS_TO_PROCESS[@]} " =~ " $yesterday " ]] && DAYS_TO_PROCESS+=("$yesterday")
    # UnicitÃ© et tri
    DAYS_TO_PROCESS=($(printf "%s\n" "${DAYS_TO_PROCESS[@]}" | sort -u))
    log "INFO" "Jours Ã  traiter: ${DAYS_TO_PROCESS[*]}"
}

# =============================================================================
# PHASE 2: TÃ‰LÃ‰CHARGEMENT DES DONNÃ‰ES (SCRIPTS DE PRODUCTION)
# =============================================================================


download_active_datasets() {
    log "INFO" "ğŸ“¥ PHASE 2: TÃ©lÃ©chargement ciblÃ© pour les jours Ã  traiter"
    # VÃ©rifier que les scripts de production existent
    local required_scripts=(
        "$SCRIPT_DIR/smart-fetch.sh"
        "$SCRIPT_DIR/generate-historical-data.sh"
    )
    for script in "${required_scripts[@]}"; do
        if [ ! -f "$script" ]; then
            log "ERROR" "Script de production manquant: $script"
            exit 1
        fi
    done
    log "INFO" "âœ… Tous les scripts de production sont disponibles"
    # RÃ©cupÃ©rer la liste des datasets actifs (auto_download: true)
    local datasets=($(jq -r '[.enabled_datasets // {} | to_entries[]] | .[] | select(.value.auto_download == true) | .key' "$CONFIG_DIR/datasets-status.json"))
    if [ ${#datasets[@]} -eq 0 ]; then
        log "WARN" "Aucun dataset actif trouvÃ© pour le tÃ©lÃ©chargement."
        return 1
    fi
    for day in "${DAYS_TO_PROCESS[@]}"; do
        local smartfetch_failed=0
        for dataset_key in "${datasets[@]}"; do
            # Conversion dataset_key (points) -> chemin relatif (slashs)
            local dataset_path=$(echo "$dataset_key" | tr '.' '/')
            local images_dir="$DATA_DIR/$dataset_path/$day"
            # Suppression des images corrompues (taille nulle) avant tÃ©lÃ©chargement
            local corrupted_count=$(find "$images_dir" -type f \( -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" \) -size 0 -delete -print | wc -l)
            if [ "$corrupted_count" -gt 0 ]; then
                log "WARN" "    ğŸ§¹ $corrupted_count image(s) corrompue(s) supprimÃ©e(s) dans $images_dir (avant tÃ©lÃ©chargement)"
            fi
            log "INFO" "ğŸ“¥ TÃ©lÃ©chargement des images pour $dataset_key le $day"
            if bash "$SCRIPT_DIR/smart-fetch.sh" dataset "$dataset_key" "$day" "$day" 2>&1 | tee -a "$LOG_FILE"; then
                log "INFO" "âœ… Images tÃ©lÃ©chargÃ©es pour $dataset_key le $day"
            else
                log "WARN" "âš ï¸ smart-fetch.sh a Ã©chouÃ© pour $dataset_key le $day"
                smartfetch_failed=1
            fi
        done
        if [ "$smartfetch_failed" -eq 1 ]; then
            log "INFO" "â†ªï¸ Tentative de gÃ©nÃ©ration de profondeur temporelle pour $day (au moins un dataset en Ã©chec)"
            if bash "$SCRIPT_DIR/generate-historical-data.sh" "$day" "$day" 2>&1 | tee -a "$LOG_FILE"; then
                log "INFO" "âœ… generate-historical-data.sh terminÃ© pour $day"
            else
                log "ERROR" "âŒ Ã‰chec du tÃ©lÃ©chargement pour au moins un dataset le $day"
            fi
        fi
    done
    # VÃ©rifier que des donnÃ©es ont Ã©tÃ© tÃ©lÃ©chargÃ©es
    local image_count=$(find "$DATA_DIR" -name "*.jpg" -type f | wc -l)
    log "INFO" "ğŸ“Š Images tÃ©lÃ©chargÃ©es: $image_count"
    if [ "$image_count" -eq 0 ]; then
        log "WARN" "âš ï¸ Aucune image tÃ©lÃ©chargÃ©e"
    fi
    log "INFO" "âœ… Phase de tÃ©lÃ©chargement terminÃ©e"
}

# =============================================================================
# PHASE 3: GÃ‰NÃ‰RATION DES VIDÃ‰OS (SCRIPTS DE PRODUCTION)
# =============================================================================


generate_daily_videos() {
    log "INFO" "ğŸ¬ PHASE 3: GÃ©nÃ©ration vidÃ©o ciblÃ©e pour les jours Ã  traiter"
    if [ ! -f "$SCRIPT_DIR/generate-daily-video.sh" ]; then
        log "ERROR" "Script de production manquant: generate-daily-video.sh"
        exit 1
    fi
    local image_count=$(find "$DATA_DIR" -name "*.jpg" -type f | wc -l)
    if [ "$image_count" -eq 0 ]; then
        log "WARN" "Aucune image trouvÃ©e pour gÃ©nÃ©rer des vidÃ©os"
        return 0
    fi
    # RÃ©cupÃ©rer la liste des datasets actifs (comme pour le tÃ©lÃ©chargement)
    local datasets=($(jq -r '[.enabled_datasets // {} | to_entries[]] | .[] | select(.value.auto_download == true) | .key' "$CONFIG_DIR/datasets-status.json"))
    for day in "${DAYS_TO_PROCESS[@]}"; do
        log "INFO" "  ğŸ¬ GÃ©nÃ©ration vidÃ©o et playlist pour $day"
        for dataset_key in "${datasets[@]}"; do
            # Conversion dataset_key (points) -> chemin relatif (slashs)
            local dataset_path=$(echo "$dataset_key" | tr '.' '/')
            local images_dir="$DATA_DIR/$dataset_path/$day"
            # Suppression des images corrompues (taille nulle)
            local corrupted_count=$(find "$images_dir" -type f \( -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" \) -size 0 -delete -print | wc -l)
            if [ "$corrupted_count" -gt 0 ]; then
                log "WARN" "    ğŸ§¹ $corrupted_count image(s) corrompue(s) supprimÃ©e(s) dans $images_dir"
            fi
            local img_count=$(find "$images_dir" -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" -type f 2>/dev/null | wc -l)
            if [ "$img_count" -eq 0 ]; then
                log "INFO" "    â© Aucune image pour $dataset_key le $day, gÃ©nÃ©ration vidÃ©o sautÃ©e."
                continue
            fi
            log "INFO" "    ğŸ“¹ $dataset_key pour $day (chemin: $images_dir)"
            bash "$SCRIPT_DIR/generate-daily-video.sh" "$dataset_key" "$day" >> "$LOG_FILE" 2>&1 || {
                log "WARN" "Ã‰chec gÃ©nÃ©ration vidÃ©o pour $dataset_key le $day (chemin: $images_dir)"
            }
        done
    done
    # Nouveau compteur : nombre de couples segment_000.ts + playlist.m3u8
    local hls_dirs=$(find "$DATA_DIR/hls" -type d)
    local video_count=0
    for dir in $hls_dirs; do
        if [ -f "$dir/segment_000.ts" ] && [ -f "$dir/playlist.m3u8" ]; then
            video_count=$((video_count+1))
        fi
    done
    log "INFO" "ğŸ“Š VidÃ©os gÃ©nÃ©rÃ©es (couples ts/m3u8): $video_count"
    log "INFO" "âœ… Phase de gÃ©nÃ©ration vidÃ©o terminÃ©e"
}

# =============================================================================
# PHASE 4: CRÃ‰ATION DES PLAYLISTS
# =============================================================================

create_playlists() {
    log "INFO" "ğŸ“‹ PHASE 4: CrÃ©ation des playlists HLS"
    
    # Les playlists sont normalement crÃ©Ã©es par generate-daily-video.sh
    # VÃ©rifions qu'elles existent et comptons-les
    
    local playlist_count=$(find "$DATA_DIR/hls" -name "playlist.m3u8" -type f | wc -l)
    local segment_count=$(find "$DATA_DIR/hls" -name "*.ts" -type f | wc -l)
    
    log "INFO" "Playlists HLS crÃ©Ã©es: $playlist_count"
    log "INFO" "Segments vidÃ©o crÃ©Ã©s: $segment_count"
    
    if [ "$playlist_count" -gt 0 ]; then
        log "INFO" "Structure des playlists:"
        find "$DATA_DIR/hls" -name "playlist.m3u8" -type f | head -5 | while read -r playlist; do
            local rel_path=$(echo "$playlist" | sed "s|$DATA_DIR/||")
            log "INFO" "  - $rel_path"
        done
        
        if [ "$playlist_count" -gt 5 ]; then
            log "INFO" "  ... et $((playlist_count - 5)) autres"
        fi
    fi
    
    log "INFO" "âœ… Playlists HLS disponibles"
}

# =============================================================================
# PHASE 5: VALIDATION ET RAPPORT
# =============================================================================

generate_report() {
    log "INFO" "ğŸ“Š PHASE 5: GÃ©nÃ©ration du rapport final"
    
    # Statistiques finales
    local total_images=$(find "$DATA_DIR" -name "*.jpg" -type f | wc -l)
    local total_videos=0
    for day in "$@"; do
        for dataset_key in "${datasets[@]}"; do
            local hls_dir="$DATA_DIR/hls/$dataset_key/$day"
            if [ -f "$hls_dir/segment_000.ts" ] && [ -f "$hls_dir/playlist.m3u8" ]; then
                total_videos=$((total_videos+1))
            fi
        done
    done
    local total_playlists=$(find "$DATA_DIR/hls" -name "playlist.m3u8" -type f | wc -l)
    local total_segments=$(find "$DATA_DIR/hls" -name "*.ts" -type f | wc -l)
    local data_size=$(du -sh "$DATA_DIR" 2>/dev/null | cut -f1)
    
    echo ""
    echo "========================================="
    echo "ğŸ“Š RAPPORT FINAL - TEST COMPLET"
    echo "========================================="
    echo "ğŸ–¼ï¸  Images tÃ©lÃ©chargÃ©es: $total_images"
    echo "ğŸ¬ VidÃ©os gÃ©nÃ©rÃ©es: $total_videos"  
    echo "ğŸ“‹ Playlists HLS: $total_playlists"
    echo "ğŸï¸  Segments vidÃ©o: $total_segments"
    echo "ğŸ’¾ Taille totale des donnÃ©es: $data_size"
    echo ""
    
    if [ "$total_images" -gt 0 ] && [ "$total_playlists" -gt 0 ]; then
        echo "âœ… TEST COMPLET RÃ‰USSI!"
        echo ""
        echo "ğŸš€ L'application frontend peut maintenant:"
        echo "   - Afficher les datasets disponibles"
        echo "   - Lire les vidÃ©os satellitaires"
        echo "   - Naviguer dans les playlists HLS"
        echo ""
        echo "ğŸŒ DÃ©marrez le serveur avec: npm run dev"
        echo "ğŸ“± AccÃ©dez Ã : http://localhost:10000"
    else
        echo "âŒ TEST INCOMPLET"
        echo "   VÃ©rifiez les logs pour plus de dÃ©tails: $LOG_FILE"
    fi
    
    echo "========================================="
    echo ""
}

# =============================================================================
# FONCTION PRINCIPALE
# =============================================================================


main() {
    echo ""
    echo "ğŸŒ EarthImagery - Test de bout en bout (Scripts de Production)"
    echo "============================================================="
    echo ""
    echo "Ce test exÃ©cute directement les scripts qui tourneront en production:"
    echo "  ğŸ“¥ Phase 2: TÃ©lÃ©chargement ciblÃ©"
    echo "  ğŸ¬ Phase 3: GÃ©nÃ©ration vidÃ©o ciblÃ©e"
    echo "  ğŸ“‹ Phase 4: Validation des playlists HLS gÃ©nÃ©rÃ©es"
    echo ""
    # Initialisation
    create_directories
    check_dependencies
    # DÃ©tection des jours Ã  traiter
    detect_days_to_process
    # ExÃ©cution des phases avec les scripts de production
    download_active_datasets
    generate_daily_videos
    create_playlists
    # Compteur strictement local : nombre de couples HLS gÃ©nÃ©rÃ©s dans cette exÃ©cution
    local local_video_count=0
    local datasets=($(jq -r '[.enabled_datasets // {} | to_entries[]] | .[] | select(.value.auto_download == true) | .key' "$CONFIG_DIR/datasets-status.json"))
    for day in "${DAYS_TO_PROCESS[@]}"; do
        for dataset_key in "${datasets[@]}"; do
            local hls_dir="$DATA_DIR/hls/$dataset_key/$day"
            if [ -f "$hls_dir/segment_000.ts" ] && [ -f "$hls_dir/playlist.m3u8" ]; then
                local_video_count=$((local_video_count+1))
            fi
        done
    done
    log "INFO" "ğŸ“Š Couples HLS gÃ©nÃ©rÃ©s dans cette exÃ©cution: $local_video_count"
    generate_report "${DAYS_TO_PROCESS[@]}"
    # Suppression des images sauf aujourd'hui et la veille
    local today=$(date +%Y-%m-%d)
    local yesterday=$(date -d "yesterday" +%Y-%m-%d)
    log "INFO" "ğŸ§¹ Suppression de toutes les images sauf celles du jour courant ($today) et de la veille ($yesterday) dans DATA_DIR"
    find "$DATA_DIR" -name "*.jpg" -type f | while read -r img; do
        # Extraire la date du chemin (suppose /YYYY-MM-DD/ dans le chemin)
        img_date=$(echo "$img" | grep -oE "/[0-9]{4}-[0-9]{2}-[0-9]{2}/" | tr -d "/")
        if [ "$img_date" != "$today" ] && [ "$img_date" != "$yesterday" ]; then
            rm -f "$img"
        fi
    done
    log "INFO" "ğŸ‰ Test complet terminÃ© - Log disponible: $LOG_FILE"
}

# =============================================================================
# POINT D'ENTRÃ‰E
# =============================================================================

if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
